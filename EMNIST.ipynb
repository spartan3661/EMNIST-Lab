{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchmetrics import Accuracy, Precision, Recall, F1Score\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.json\", 'r') as data:\n",
    "    config_file = json.load(data)\n",
    "\n",
    "print(config_file[\"model_folder_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "train_set = torchvision.datasets.EMNIST(root=\"/data\", \n",
    "                                        split=\"byclass\", \n",
    "                                        train=True, \n",
    "                                        download=True, \n",
    "                                        transform=transform)\n",
    "\n",
    "val_set = torchvision.datasets.EMNIST(root=\"/data\",\n",
    "                                      split=\"byclass\",\n",
    "                                      train=False,\n",
    "                                      download=True,\n",
    "                                      transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image, train_label = train_set[800]\n",
    "test_image, test_label = val_set[20]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(train_image.squeeze(), cmap='gray')\n",
    "plt.title(f'Train Label: {train_label}')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(test_image.squeeze(), cmap='gray')\n",
    "plt.title(f'Test Label: {test_label}')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(train_set, batch_size=config_file[\"hyper_parameters\"][\"batch_size\"], shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_data_loader = DataLoader(val_set, batch_size=config_file[\"hyper_parameters\"][\"batch_size\"], shuffle=True, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for batch in train_data_loader:\n",
    "    image, label = batch\n",
    "    print(image.shape)\n",
    "    print(label.shape)\n",
    "    print(\"\\n\")\n",
    "    counter += 1\n",
    "    if counter > 40:\n",
    "        break\n",
    "\n",
    "\n",
    "counter = 0\n",
    "for batch in val_data_loader:\n",
    "    image, label = batch\n",
    "    print(image.shape)\n",
    "    print(label.shape)\n",
    "    print(\"\\n\")\n",
    "    counter += 1\n",
    "    if counter > 40:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (images, labels) in enumerate(val_data_loader):\n",
    "    print(f\"Batch {batch_idx + 1}\")\n",
    "    print(f\"Images shape: {images.shape}\")\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMNISTClassifier(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=64, kernel_size=3):\n",
    "        super(EMNISTClassifier, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2) #remember input/stride!!!\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 7 * 7, 256)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc2 = nn.Linear(256, 62)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = EMNISTClassifier().to(device)\n",
    "summary(model, input_size=(1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = Accuracy(task=\"multiclass\", num_classes=62).to(device)\n",
    "precision = Precision(task=\"multiclass\", num_classes=62, average='macro').to(device)\n",
    "recall = Recall(task=\"multiclass\", num_classes=62, average='macro').to(device)\n",
    "f1 = F1Score(task=\"multiclass\", num_classes=62, average='macro').to(device)\n",
    "\n",
    "writer = SummaryWriter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config_file[\"hyper_parameters\"][\"lr\"])\n",
    "num_epochs = config_file[\"hyper_parameters\"][\"num_epochs\"]\n",
    "\n",
    "#train\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss, epoch_accuracy, epoch_precision, epoch_recall, epoch_f1 = 0, 0, 0, 0, 0\n",
    "    progress_bar_train = tqdm(train_data_loader, desc=f'Epoch [{epoch+1}/{num_epochs}]', leave=True)\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(progress_bar_train):\n",
    "        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "\n",
    "        predictions = model(images)\n",
    "        loss = loss_fn(predictions, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        preds = torch.argmax(predictions, dim=1)\n",
    "        batch_accuracy = accuracy(preds, labels).item()\n",
    "        batch_precision = precision(preds, labels).item()\n",
    "        batch_recall = recall(preds, labels).item()\n",
    "        batch_f1 = f1(preds, labels).item()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_accuracy += batch_accuracy\n",
    "        epoch_precision += batch_precision\n",
    "        epoch_recall += batch_recall\n",
    "        epoch_f1 += batch_f1\n",
    "\n",
    "        progress_bar_train.set_postfix({\n",
    "            'Batch Loss': loss.item(),\n",
    "            'Accuracy': batch_accuracy,\n",
    "            'Precision': batch_precision,\n",
    "            'Recall': batch_recall,\n",
    "            'F1': batch_f1\n",
    "        })\n",
    "\n",
    "    #eval\n",
    "    model.eval()\n",
    "    val_loss, val_accuracy, val_precision, val_recall, val_f1 = 0, 0, 0, 0, 0\n",
    "    progress_bar_val = tqdm(val_data_loader, desc=f'Validation [{epoch+1}/{num_epochs}]', leave=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in progress_bar_val:\n",
    "            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "\n",
    "            predictions = model(images)\n",
    "            loss = loss_fn(predictions, labels)\n",
    "\n",
    "            preds = torch.argmax(predictions, dim=1)\n",
    "            batch_accuracy = accuracy(preds, labels).item()\n",
    "            batch_precision = precision(preds, labels).item()\n",
    "            batch_recall = recall(preds, labels).item()\n",
    "            batch_f1 = f1(preds, labels).item()\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_accuracy += batch_accuracy\n",
    "            val_precision += batch_precision\n",
    "            val_recall += batch_recall\n",
    "            val_f1 += batch_f1\n",
    "\n",
    "            progress_bar_val.set_postfix({\n",
    "                'Val Loss': loss.item(),\n",
    "                'Accuracy': batch_accuracy,\n",
    "                'Precision': batch_precision,\n",
    "                'Recall': batch_recall,\n",
    "                'F1': batch_f1\n",
    "            })\n",
    "            progress_bar_val.refresh()\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_data_loader)\n",
    "    avg_accuracy = epoch_accuracy / len(train_data_loader)\n",
    "    avg_precision = epoch_precision / len(train_data_loader)\n",
    "    avg_recall = epoch_recall / len(train_data_loader)\n",
    "    avg_f1 = epoch_f1 / len(train_data_loader)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_data_loader)\n",
    "    avg_val_accuracy = val_accuracy / len(val_data_loader)\n",
    "    avg_val_precision = val_precision / len(val_data_loader)\n",
    "    avg_val_recall = val_recall / len(val_data_loader)\n",
    "    avg_val_f1 = val_f1 / len(val_data_loader)\n",
    "\n",
    "    writer.add_scalar('Loss/train', avg_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/train', avg_accuracy, epoch)\n",
    "    writer.add_scalar('Precision/train', avg_precision, epoch)\n",
    "    writer.add_scalar('Recall/train', avg_recall, epoch)\n",
    "    writer.add_scalar('F1_Score/train', avg_f1, epoch)\n",
    "\n",
    "    writer.add_scalar('Loss/val', avg_val_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/val', avg_val_accuracy, epoch)\n",
    "    writer.add_scalar('Precision/val', avg_val_precision, epoch)\n",
    "    writer.add_scalar('Recall/val', avg_val_recall, epoch)\n",
    "    writer.add_scalar('F1_Score/val', avg_val_f1, epoch)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = config_file[\"model_folder_path\"]\n",
    "if not os.path.exists(model_folder):\n",
    "    os.mkdir(model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, f\"{model_folder}/EMNIST.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
